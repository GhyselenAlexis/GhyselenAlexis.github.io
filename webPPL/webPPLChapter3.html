<html>
<head>
<meta charset="UTF-8"> 
<script src="webppl.js"></script> <!-- compiled webppl library; get this from https://github.com/probmods/webppl -->
<script src="webppl-editor.js"></script>
<script src="webppl-viz.js"></script>
<script src="draw.js"></script>
<script src="jquery.js"></script>
<script src="paper.js"></script>
<script src="underscore.js"></script>
<script src="box2d.js"></script>
<script src="physics.js"></script>
<link rel="stylesheet" href="webppl-editor.css">
<link rel="stylesheet" href="webppl-viz.css">
<link rel="stylesheet" href="styles.css"> 
<link rel="stylesheet" href="w3.css"> 

</head>
<body>

    <div class="w3-bar w3-black">
        <a href="webPPLModule.html" class="w3-bar-item w3-button w3-mobile">Intro</a>
        <a href="webPPLChapter1.html" class="w3-bar-item w3-button w3-mobile">Chapter 1: The Core Language</a>
        <a href="webPPLChapter2.html" class="w3-bar-item w3-button w3-mobile">Chapter 2: Forward Models</a>
        <a href="webPPLChapter3.html" class="w3-bar-item w3-button w3-mobile w3-green">Chapter 3: Conditioning and Inference</a>
    </div> 
  
<h3> Conditioning </h3>
 <p>
<pre>
// Decomment the conditions to observe the belief on the distribution of A 
var model = function() {
  var A = flip()
  var B = flip()
  var C = flip()
  // condition(A + B + C == 3)
  // condition(A + B + C >= 2) 
  // condition(B == 0)
  return {'A': A}
}
var dist = Infer(model)
viz(dist)
</pre> 

<pre>
// Conditioning without inferring does not make sense
// Try to uncomment the condition below
var model = function() {
  var A = flip()
  var B = flip()
  var C = flip()
  // condition(A + B + C >= 2) 
  return {'A': A}
}

model() 
</pre> 

</p>

<h3> Enumerate </h3>

<p> 
<pre> 
var model = function() {
  var A = flip()
  var B = flip()
  var C = flip()
  condition(A + B + C >= 2) 
  return {'A': A, 'B': B, 'C' : C}
}
// We only need 8 executions to see all the paths for this example. 
var truedist = Infer(model)
var dist = Infer({method: "enumerate", maxExecutions: 8, strategy : "likelyFirst"},model)
viz.table(truedist)
viz.table(dist)
</pre>
<pre>
///fold:
var model = function() {
  var A = flip()
  var B = flip()
  var C = flip()
  condition(A + B + C >= 2) 
  return {'A': A, 'B': B, 'C' : C}
}
/// 
// If we remove one execution, we see that the inference fails to give the precise probabilities.  
var truedist = Infer(model)
var dist = Infer({method: "enumerate", maxExecutions: 7, strategy : "likelyFirst"},model)
viz.table(truedist)
viz.table(dist)
</pre>
<pre>
// Let us modify the program a bit to change the likelyFirst strategy
// We use biaised coins more likely to return true. 
var model = function() {
  var A = flip(0.6)
  var B = flip(0.6)
  var C = flip(0.6)
  condition(A + B + C >= 2) 
  return {'A': A, 'B': B, 'C' : C}
}
var truedist = Infer(model)
var dist = Infer({method: "enumerate", maxExecutions: 7, strategy : "likelyFirst"},model)
viz.table(truedist)
viz.table(dist)
// This time, enumration can estimate well the probabilities. Why ? 
// Remove the condition to have an hint. 
</pre>

<pre>
// Then, this should not work... 
var model = function() {
  var A = flip(0.4)
  var B = flip(0.4)
  var C = flip(0.4)
  condition(A + B + C >= 2) 
  return {'A': A, 'B': B, 'C' : C}
}
var truedist = Infer(model)
var dist = Infer({method: "enumerate", maxExecutions: 7, strategy : "likelyFirst"},model)
viz.table(truedist)
viz.table(dist)
// As expected. 
</pre>
</p>

<p>
A bit of more advanced reasoning: we saw that the "likelyFirst" strategy uses an heuristic dependent on the probabilities of each path.
But in practice, we do not want to modify the generative model. Do we have another solution ? 
<pre>
// In fact, factor can be used to guide the heuristics. 
// Here, we remove some weight to the path where A is false
var model = function() {
  var A = flip()
  if (A == false) {factor(-10)};
  var B = flip()
  var C = flip()
  // But we give back the weight after
  if (A == false) {factor(+10)};
  condition(A + B + C >= 2)
  return {'A': A, 'B': B, 'C' : C}
}
// This time it works. 
var truedist = Infer(model)
var dist = Infer({method: "enumerate", maxExecutions: 6, strategy : "likelyFirst"},model)
viz.table(truedist)
viz.table(dist)
// You can remove the condition to see all the paths 
// Remove the second factor, what is the problem ? Why ? 
</pre></p>

<h3> Rejection Sampling </h3>

<p><pre>
// Direct Implementation of Rejection Sampling 
var takeSample = function () {
  var A = flip()
  var B = flip()
  var C = flip()
  var D = A + B + C
  // If we do not satisfy the condition, we try again
  return D >= 2 ? A : takeSample()
}
viz(repeat(1000, takeSample))
viz.table(repeat(1000, takeSample))
</pre>
<pre>
// Using the Inference Operator
var model = function () {
  var A = flip()
  var B = flip()
  var C = flip()
  var D = A + B + C
  condition(D >= 2)
  return A
}
var dist = Infer({method: 'rejection', samples: 1000}, model)
viz(dist)
viz.table(dist)
</pre>

</p>

<h3> Example 1 : Inverse Physics</h3>

<p>
<pre>
// Makes a floor with evenly spaced buckets
var bins = function (xmin, xmax, width) {
  return ((xmax < xmin + width)
          // floor
          ? {shape: 'rect', static: true, dims: [400, 10], x: 175, y: 500}
          // bins
          : [{shape: 'rect', static: true, dims: [1, 10], x: xmin, y: 490}].concat(bins(xmin + width, xmax, width))
         )
}

// Add two fixed circles
var world = [{shape: 'circle', static: true, dims: [60], x: 60, y: 200},
             {shape: 'circle', static: true, dims: [30], x: 300, y: 300}].concat(bins(-1000, 1000, 25))

// The random block has an random initial starting state, random on the horizontal line (in x) 
var randomBlock = function () {
  return {shape: 'circle', static: false, dims: [10], x: uniform(0, worldWidth), y: 0}
}
// The number 1000 indicates the number of "steps" you want to simulate 
physics.animate(1000, [randomBlock()].concat(world))
</pre>

<pre>
///fold: 
// Makes a floor with evenly spaced buckets
var bins = function (xmin, xmax, width) {
  return ((xmax < xmin + width)
          // floor
          ? {shape: 'rect', static: true, dims: [400, 10], x: 175, y: 500}
          // bins
          : [{shape: 'rect', static: true, dims: [1, 10], x: xmin, y: 490}].concat(bins(xmin + width, xmax, width))
         )
}

// Add two fixed circles
var world = [{shape: 'circle', static: true, dims: [60], x: 60, y: 200},
             {shape: 'circle', static: true, dims: [30], x: 300, y: 300}].concat(bins(-1000, 1000, 25))

// The random block has an random initial starting state, random on the horizontal line (in x) 
var randomBlock = function () {
  return {shape: 'circle', static: false, dims: [10], x: uniform(0, worldWidth), y: 0}
}
/// 
// Get the Ball (filter the only non static object in the world)
var getBallX = function(world) {
  var ball = filter(function(obj) { return !obj.static }, world)[0];
  return ball.x;
}

// Gives the actual observation of the ball. 
var observedX = 160;

// Generative Model 
var model = function() {
  var initState = world.concat([randomBlock()])
  var initX = getBallX(initState);
  var finalState = physics.run(1000, initState);
  var finalX = getBallX(finalState);
  observe(Gaussian({mu: finalX, sigma: 10}), observedX)
  return {initX: initX}
}

// Infer the initial distribution, using MCMC
var initialXDist = Infer(
  {method: 'MCMC',
   samples: 100,
   lag: 10,
   callbacks: [editor.MCMCProgress()]
  },
  model);

viz.density(initialXDist, {bounds: [0,350]})
</pre>

</p>

<h3> Medical Diagnosis </h3>

<p><pre>
var dist = Infer({method: 'enumerate'},
  function () {
    var lungCancer = flip(0.01)
    var TB = flip(0.005)
    var cold = flip(0.2)
    var stomachFlu = flip(0.1)
    var other = flip(0.1)

    var cough = ((cold && flip(0.5)) ||
                 (lungCancer && flip(0.3)) ||
                 (TB && flip(0.7)) ||
                 (other && flip(0.01)))

    var fever = ((cold && flip(0.3)) ||
                 (stomachFlu && flip(0.5)) ||
                 (TB && flip(0.2)) ||
                 (other && flip(0.01)))

    var chestPain = ((lungCancer && flip(0.4)) ||
                     (TB && flip(0.5)) ||
                     (other && flip(0.01)))

    var shortnessOfBreath = ((lungCancer && flip(0.4)) ||
                             (TB && flip(0.5)) ||
                             (other && flip(0.01)))

    condition(cough && fever && chestPain && shortnessOfBreath)
    return {lungCancer: lungCancer, TB: TB}
})
viz(dist)
viz.marginals(dist)
viz.table(dist)
</pre></p>

<h3> Bayesian Data Analysis</h3>

<p> 
Poll example, taken from <a href="https://probmods.org/chapters/bayesian-data-analysis.html">Probmods Chapter 7</a>
    <pre>

// observed data
var k = 1 // number of people who support candidate A
var n = 20  // number of people asked

var model = function() {

    // true population proportion who support candidate A
    var p = uniform(0, 1);

    // Observed k people support "A"
    // Assuming each person's response is independent of each other
    observe(Binomial({p : p, n: n}), k);

    // predict what the next n will say
    var posteriorPredictive = binomial(p, n);

    // recreate model structure, without observe
    var prior_p = uniform(0, 1);
    var priorPredictive = binomial(prior_p, n);

    return {
        prior: prior_p, priorPredictive : priorPredictive,
        posterior : p, posteriorPredictive : posteriorPredictive
    };
}

var posterior = Infer(model);

viz.marginals(posterior)
</pre>
Linear Regression Example 
<pre>
//Observed data
var observedData = [{"x":0,"y":0},{"x":1,"y":5.2},{"x":2,"y":9.4},{"x":3,"y":15},{"x":4,"y":20.5},{"x":5,"y":24.3}]
    
// Create a drawing of size 500,500
var myDraw = Draw(500, 500, true)
    
//Intermediate functions to draw

//Scale a point to the image
var scale = function(p) {
      var newX = 20 + p.x * 75
      var newY = 480 - p.y * 15
      return{"x":newX,"y":newY}
}
    
// Draw a list of data points
var drawData = function(img,obs) {
    var scaleData = map(scale,obs)
    map(function(p) {
      img.circle(p.x, p.y, 3, 'black', 'white')
    }, scaleData)
}
    
// Draw a linear function 
var drawLinFun = function(img,f) { 
      var a = scale({"x":0, "y":f(0)})
      var b = scale({"x":5.5, "y":f(5.5)})
      img.line(a.x,a.y,b.x,b.y,1,0.01,"red")
}
    
// Make a function from a coefficient
var makeFun = function(a) {
    return ( function(x) {
        return(a * x)
      })
}
    
//Compute a Random Line, and observe data
// The prior distribution on a is the uniform one 
// The generative model take into account some noises, expressed by a gaussian. 
var randomLine = function() {
    var a = uniform(0,10)
    var f = makeFun(a)
      
    var obsFn = function(datum){
        observe(Gaussian({mu: f(datum.x), sigma: 2}), datum.y)
    }
    mapData({data: observedData}, obsFn)
      
    return a      
}

// Infer the distribution on coefficients
var post = Infer(randomLine)
    
// Draw samples from the inferred distribution, to have some visual intuition about the distribution
var randomDraw = function() {
    var a = sample(post)
    drawLinFun(myDraw,makeFun(a))
}

//Visualize the distribution on coefficients
viz(post)
    
// Draw the data 
drawData(myDraw,observedData)
// Draw the samples from the marginal distribution 
repeat(1000,randomDraw)
    
print("The value should be around 5")
</pre>

Fair Coin or Trick Coin ? 
<pre>
// Our degree of belief for the fact that the coin is fair 
var fairPrior = 0.999
// The observed list of data 
var obsData = repeat(5,function() {'h'})

//Make a Coin of a Given Weight
var makeCoin = function(x) {
    return function() {
        (flip(x)) ? 'h' : 't'
    }
}

//Generative Model 
var model = function() {
    //We create the coin acording to our belief 
    var isFair = flip(fairPrior)
    var coin = (isFair) ? makeCoin(0.5) : makeCoin(0.95)
    // A standard way to compare data with a distribution is to use "map"
    mapData({data: obsData},function(datum) {condition(coin() == datum)})
    // mapData is similar to map, but you inform the inference that all calls are independent
    return isFair
}

var post = Infer(model)
viz(post)
</pre>
<pre>
// We can be even more precise in our prior distribution.
// We can try to infer the actual weight of the coin, by believing that trick coin could have any weight > 0.5


// Our degree of belief for the fact that the coin is fair 
var fairPrior = 0.999
// The observed list of data 
var obsData = repeat(10,function() {'h'})

//Generative Model 
var model = function() {
    //We create the coin acording to our belief 
    var isFair = flip(fairPrior)
    // The weight is either 0.5, or a trick coin that prefer head 
    var weight = (isFair) ? 0.5 : uniform(0.5,1)
    var dist = Bernoulli({p : weight})
    // Note that we use observe here, with a Bernoulli distribution, this optimizes the inference
    mapData({data: obsData},function(datum) {observe(dist,datum == 'h')})
    return weight
}

// We can try SMC as we alernate between observations and samples 
var post = Infer({method: 'SMC', particles : 5000},model)
viz(post)
</pre>
</p>

<h3> Inference Algorithms and MCMC</h3>
<pre>
// We take back our previous example, with unfair coin 
var baserate = 0.1

// We try the rejection method. If the baserate is too low, most samples will be rejected. 
var infModel = function(){
  Infer({method: 'rejection', samples: 100}, function(){
    var A = flip(baserate)
    var B = flip(baserate)
    var C = flip(baserate)
    condition(A+B+C >= 2)
    return A})
}

//With the lodash library, we can compute the average time of an inference algorithm
var time = function(foo, trials) {
  var start = _.now()
  var ret = repeat(trials, foo)
  var end = _.now()
  return (end-start)/trials
}

time(infModel, 10)
// Try to lower the baserate to 0.01, it should already be slow. 
</pre>
On this example, we could also use "enumerate"
<pre>
///fold:
var time = function(foo, trials) {
  var start = _.now()
  var ret = repeat(trials, foo)
  var end = _.now()
  return (end-start)/trials
}
///

var baserate = 0.1

var infModel = function(){
  Infer({method: 'enumerate'}, function(){
    var A = flip(baserate)
    var B = flip(baserate)
    var C = flip(baserate)
    condition(A+B+C >= 2)
    return A})
}

time(infModel, 10)
// Try to lower the baserate. What is the impact on time ? Why ? 
</pre>

<pre>
///fold:
//a timing utility: run 'foo' 'trials' times, report average time.
var time = function(foo, trials) {
  var start = _.now()
  var ret = repeat(trials, foo)
  var end = _.now()
  return (end-start)/trials
}
///

// However, enumerate does not sacle well with the number of samples. 
// Let us modify the program to test this
var baserate = 0.1
var numFlips = 3

var infModel = function(){
  Infer({method: 'enumerate'}, function(){
    var choices = repeat(numFlips, function(){flip(baserate)})
    // Sum computes the sum of all elements in an array 
    condition(sum(choices) >= 2)
    return choices[0]})
}

time(infModel, 10)
// Try this program with 15 flips. And for rejection, what is the impact of increasing the number of flips ? Why ?
</pre>

<pre>
///fold:
//a timing utility: run 'foo' 'trials' times, report average time.
var time = function(foo, trials) {
  var start = _.now()
  var ret = repeat(trials, foo)
  var end = _.now()
  return (end-start)/trials
}
///
// Finally, let's try the MCMC algorithm this time. 
var baserate = 0.1
var numFlips = 3

var infModel = function(){
  Infer({method: 'MCMC', lag: 100}, function(){
    var choices = repeat(numFlips, function(){flip(baserate)})
    condition(sum(choices) >= 2)
    return choices[0]})
}

time(infModel, 10)
// You can even try baserate = 0.001 and numFlips = 100 and it should still be rather efficient. 
// However, what we cannot see here is that what we gain in efficiency, we lose in precision. 
// But this is a standard tradeoff. 
</pre>

<h3> Markov Chain Monte Carlo</h3>
<p><pre>
// Here is a simple Markov Chain 
var states = ['S', 'C'];
var transitionProbs = {S: [.3, .7], C: [.5, .5]}

// The categorical distribution is exactly what we need here
var transition = function(state){
  return categorical({vs: states, ps: transitionProbs[state]})
}

// We repeat n times the transition function
var chain = function(state, n){
  return (n == 0 ? state : chain(transition(state), n-1))
}

print("State after 10 steps:")
viz.hist(repeat(1000,function() {chain('S',10)}))
viz.hist(repeat(1000,function() {chain('C',10)}))

print("State after 25 steps:")
viz.hist(repeat(1000,function() {chain('S',25)}))
viz.hist(repeat(1000,function() {chain('C',25)}))

print("State after 50 steps:")
viz.hist(repeat(1000,function() {chain('S',50)}))
viz.hist(repeat(1000,function() {chain('C',50)}))
</pre></p>

</body>
<script>
// find all <pre> elements and set up the editor on them
var preEls = Array.prototype.slice.call(document.querySelectorAll("pre"));
preEls.map(function(el) { editor.setup(el, {language: 'webppl'}); });
</script>
</html>